{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision / OpenCV Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "    1) What is Computer Vision?\n",
    "    2) Image Processing\n",
    "        * Read, write and display image.\n",
    "    3) Geometric Transformations\n",
    "        * Crop / Resize\n",
    "        * Transformation\n",
    "    4) Binary Image Processing\n",
    "        * Thresholding\n",
    "        * Dilation\n",
    "        * Erosion\n",
    "        * Connected Component Analysis\n",
    "        * Opening\n",
    "        * Closing\n",
    "    5) Color Spaces\n",
    "    6) Image Enhancement \n",
    "    7) Image Filtering\n",
    "        * Convolution\n",
    "        * Image Blur\n",
    "        * Image Gradient\n",
    "            - First order filters\n",
    "            - Second order filters \n",
    "                - Laplacian Filter\n",
    "                - LoG ( Laplacian with Gaussian)\n",
    "         * Edge Detection\n",
    "    8) Instagram Filters\n",
    "    9) Facial Landmark Detection\n",
    "    10)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) What is computer vision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    In Computer vision, the input is an image and the output is the information derived from the image. Ex: face detection.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) What is Image Processing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    In image processing, the input is an image and output is a modified version of original image. Some of the processing on images are as follows: Image enhancement, smoothing, image compression, edge detection.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Geometric Transformation\n",
    "\n",
    "### Rotation\n",
    "rotMat = getRotationMatrix2D(center, angle, scale)\n",
    "\n",
    "### Transformation \n",
    "\n",
    "**Linear transformation, the straight lines in original image remain straight lines in the transformed images.**\n",
    "\n",
    "    1) Translation               (preserves orientation, does just displacement)\n",
    "    2) Euclidean Tranformation   (preserves length)\n",
    "    \n",
    "   **Euclidean = Rotation + Translation**\n",
    "   \n",
    "    3) Similarity Transformation (preserves angles, parallelism and straight lines, does just rotation and scaling)\n",
    "    \n",
    "   ** Similarity = Rotation + Translation + Scaling**\n",
    "   \n",
    "    4) Affine Transformation     (preserves parallelism, angles are NOT retained in the transformed image)\n",
    "   \n",
    "   **Affine = Translation + Rotation + Scaling**\n",
    "        \n",
    "    5) Projective Transformation (preserves straight lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Binary Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1) **Image** = pixels with different intensity values [0-255]\n",
    "  \n",
    "  2) **Binary Image** = pixels with either black (pixel value 0) or white color (pixel value 255).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Image processing algorithms \n",
    "\n",
    "**The following Morphological operations are used to clean up the images.**\n",
    "\n",
    "   1)    **Thresholding** : \n",
    "```   \n",
    "   converts the gray scale image to binary image based on the intensity of the pixels.\n",
    "   Convert the source image based on the threshold value to a binary image.\n",
    "```   \n",
    "```\n",
    "   pixel_location = (x,y)\n",
    "   \n",
    "   if src(pixel_location) > threshold:\n",
    "       dest(pixel_location) = 255; # white color\n",
    "   else:\n",
    "       dest(pixel_location) = 0; # black color\n",
    "```\n",
    "\n",
    "   2)  **Dilation** : is a process of expanding the image.\n",
    "\n",
    "   3)  **Erosion** : is a process of shrinking the image.\n",
    "   \n",
    "   [Example of Dilation and Erosion using opencv](http://docs.opencv.org/3.0beta/doc/tutorials/imgproc/erosion_dilatation/erosion_dilatation.html#morphology-1)\n",
    "       \n",
    "   4)  **Open**\n",
    "   \n",
    "   5)  **Close**\n",
    "   \n",
    "   [Example of other Mophological transformations: Open, close etc](http://docs.opencv.org/3.0-beta/doc/tutorials/imgproc/opening_closing_hats/opening_closing_hats.html#morphology-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Color Spaces\n",
    "\n",
    "   The following are the different color spaces.\n",
    "   Refer [wiki for more info.](https://en.wikipedia.org/wiki/List_of_color_spaces_and_their_uses).\n",
    "    \n",
    "  * RGB\n",
    "      - In OpenCV, the image is loaded in BGR format, that is the reverse of RGB.\n",
    "  * HSV\n",
    "      - Hue : Refers to the color of the pixel\n",
    "      - Saturation : Refers to the purity of the color.\n",
    "      - Value: Refers to the brightness of the pixel.\n",
    "      - HSV is more intuitive as it separates the color and brightness.\n",
    "      \n",
    "  * YCrCb\n",
    "      -  Y : Refers to Luma (intensity of the pixel)\n",
    "      - Cr : R - L, Red difference (amount of red in the image)\n",
    "      - Cb : B -L , Blue difference (amount of blue in the image)\n",
    "      - This is primarily used in the image compression during transmission. The Luma component can be used with higher resoultion (intensity) and Chroma compoent (different shades of the color) can be encoded with lower resolution.\n",
    "      \n",
    "  * LAB\n",
    "      -  L : Lightness (Brightness of the color)\n",
    "      -  A : a color component from Green to Magenta\n",
    "      -  B : a color component from Blue to Yellow\n",
    "  \n",
    "  The different color spaces have been designed to cater to different applications: Segmentation, transmission, display, printing etc. Some of the properties of color spaces are:\n",
    "   * Device Independence\n",
    "   * Intuitiveness\n",
    "   * Perceptual uniformity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Image Enhancement\n",
    "   *  **Desaturation Filter**: \n",
    "```\n",
    "       The Saturation channel refers to the purity of the color. So, if you want to show the pictures faded or washed out with no colors, then decreasing the saturation value will do that.\n",
    "```\n",
    "\n",
    "   * **Brightness Adjustment**:\n",
    "   \n",
    "```\n",
    "    The brightness is the measure of light falling on the object. \n",
    "    \n",
    "    In RGB space, it can be thought of as arithmetic mean of R, G and B color values. \n",
    "    To increase the brightness, change the intensity by some offset.\n",
    "    In YCrCb space, increase the Y component with some offset.\n",
    "```\n",
    "\n",
    "   * **Contrast Adjustment**:\n",
    "```\n",
    "    Contrast is difference between the brightest and darkest region in the image. Higher the difference, higher the contrast.\n",
    "```\n",
    "        - How to improve the contrast of an image?\n",
    "            - Intensity scaling \n",
    "            - [Histogram equalization.](https://en.wikipedia.org/wiki/Histogram_equalization)\n",
    "            - CLAHE (Local Area Histogram Equalizaiton)\n",
    "        \n",
    "        \n",
    "   * **Gamma Correction**:\n",
    "```\n",
    "    Is used to change the intensity of the pixels, so that the brighness and contrast are enchanced. This is done using power law Transform. \n",
    "```\n",
    "\n",
    "   * **Color Tone adjustment using Curves**\n",
    "   Refer to this [photoshop tutorial for more info.](https://helpx.adobe.com/photoshop/using/curves-adjustment.html)\n",
    "```\n",
    "    By adjusting the color, we can add warming and cooling effects to an image.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Image Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 ) What is Image Filtering?\n",
    "```\n",
    "    Enhance the image by\n",
    "        a) removing unwanted characteristics (noise)\n",
    "        b) improve the better characeristics (better contrast, etc)\n",
    "        \n",
    "   Some of the Image filtering are as follows:\n",
    "       1) Blurring\n",
    "       2) Edge Detection\n",
    "       3) Edge Enhancement\n",
    "       4) Noise Removal\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2) How is Image Filtering done?\n",
    "```\n",
    "    Image filtering is a local (neighbourhood) operation. ie., the pixel in the output image location x and y depends in the small neighbourhood of the input image (say, the kernel/filter of size 3x3).\n",
    "    \n",
    "    When the output depends on the linear combination of the input pixels then it is called as Linear Filter. Otherwise, it is called as Non Linear Filters.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3) What is a Convolution?\n",
    "\n",
    "```\n",
    "    Convolution is a basic type of image filtering. The Convolution operation needs two inputs:\n",
    "        1) Input Image. For color images, the convolution operation happens on all three R, G, and B channels separately.\n",
    "        2) A Convolution Kernel: A small matrix of numbers. The numbers can be - positive, negative or decimal.\n",
    "        \n",
    "    The output is a filtered image based on the implementation of convolution operation.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4) What are the different kinds of Image filtering?\n",
    "   There are many kinds of image filtering.\n",
    "      *  Blur\n",
    "            - In the case of Blur, the values or weights in the kernel will be 1/(n*n) for an n sized kernel.\n",
    "            - In other words, the when you sum all weights in the kernel, it would result in 1 (one).\n",
    "            - In OpenCV,\n",
    "                - dstImg = blur(srcImage, kernel_size)\n",
    "                \n",
    "        * Gaussian Blur\n",
    "            - In this case, the weights the contribution of the neighbouring pixel is based on the distance of the pixel from the center pixel.\n",
    "            \n",
    "        * Median Blur:\n",
    "            - Used to remove the salt and pepper (white and black spots) in the image.\n",
    "            - In the kernel, replace the high value in the center with the median of the neighbourhood pixel weights.\n",
    "            \n",
    "        * Bilateral Filter:\n",
    "        \n",
    "        * Image Gradients\n",
    "            - The directional change in the intensity of pixel is called gradient.\n",
    "            - PreWitt Filter\n",
    "            - Sobel Filter\n",
    "            - Second Order Derivative Filter\n",
    "                - Laplacian Filter\n",
    "                \n",
    "         * Image Sharpening\n",
    "             - Blur the image.\n",
    "             - Get the high frequency info. (basically edges) [ original image - Blur image]\n",
    "             - Put back the high freqeunce info. to the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Instagram Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Facial Landmark Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1) What is Facial Landmark Detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    To recognise the face, first you have to locate the face in the image. Once you have the bounding box, the obvious research problem is to identify the features (corners of the eye, eyebrows, mouth and tip of the nose etc.).\n",
    "    \n",
    "    In Facial Landmark Detection, the goal is to detect a few points on the face.\n",
    "    Sometimes, the Facial Landmark Detection is also referred as 'Facial Feature Detection', 'Facial Keypoint Detection', and 'Face alignment'.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2) What are the uses / applications of Facial Landmark Detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   *  Face Recognition\n",
    "   * Face Morphing\n",
    "   * Face Averaging\n",
    "   * Face Swap\n",
    "   * Virtual Makeover\n",
    "   * Blink and Drowsy Driver Detection\n",
    "   * Face filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3) How to detect landmarks in face?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a two step process:\n",
    "   *  **Face Detection**: Given an image, detect the face in the  image. ie., the top left corner of the image and width and height of the image.\n",
    "       - There are different face detectors.\n",
    "       - OpenCV uses HAAR or LBP cascades\n",
    "       - Dlib uses Histogram of Oriented Gradients features and Support Vector Machine (SVM).\n",
    "       \n",
    "   * **Landmark Detection:** It will detect the landmarks within the rectangle.\n",
    "   \n",
    "   * Paper: [Face Alignment with Regression Trees (Dlib's implementation)](http://www.csc.kth.se/~vahidk/papers/KazemiCVPR14.pdf)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4) How to improve the performance of the face detection?\n",
    "   * Compile Dlib in Optimization mode.\n",
    "   * Use Qt is Release mode / Opt mode.\n",
    "   * Resize the frame\n",
    "   * Skip frame\n",
    "   * Optimize Display - custom renderer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5) How to stablize the landmark points in the video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
